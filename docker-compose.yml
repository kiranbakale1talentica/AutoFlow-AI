services:
  # AutoFlow AI Backend Service
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: autoflow-backend
    restart: unless-stopped
    env_file:
      - .env
    ports:
      - "5000:5000"
    environment:
      - NODE_ENV=production
      - PORT=5000
      - DB_PATH=/app/data/database.db
      - CORS_ORIGIN=http://localhost:3000
      - SESSION_SECRET=${SESSION_SECRET:-autoflow-ai-secret-key-change-in-production}
      - GITHUB_CLIENT_ID=${GITHUB_CLIENT_ID}
      - GITHUB_CLIENT_SECRET=${GITHUB_CLIENT_SECRET}
      # Map EMAIL_* to SMTP_* for emailService.js compatibility
      - SMTP_HOST=${EMAIL_HOST:-smtp.gmail.com}
      - SMTP_PORT=${EMAIL_PORT:-587}
      - SMTP_USER=${EMAIL_USER}
      - SMTP_PASS=${EMAIL_PASS}
      - SMTP_FROM=${EMAIL_FROM:-autoflow@ai.com}
      - SMTP_SECURE=false
    volumes:
      - backend_data:/app/uploads
      - backend_logs:/app/logs
      - database_data:/app/data
    networks:
      - autoflow-network
    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://localhost:5000/api/health', (res) => process.exit(res.statusCode === 200 ? 0 : 1)).on('error', () => process.exit(1))"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    security_opt:
      - no-new-privileges:true
    read_only: false
    tmpfs:
      - /tmp
    cap_drop:
      - ALL
    cap_add:
      - NET_BIND_SERVICE

  # AutoFlow AI Frontend Service
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: autoflow-frontend
    restart: unless-stopped
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
      - REACT_APP_API_URL=http://localhost:5000
      - REACT_APP_WS_URL=ws://localhost:5000
    depends_on:
      backend:
        condition: service_healthy
    networks:
      - autoflow-network
    healthcheck:
      test: ["CMD", "ls", "build/index.html"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 5s
    security_opt:
      - no-new-privileges:true
    read_only: true
    tmpfs:
      - /tmp
    cap_drop:
      - ALL

  # Nginx Reverse Proxy (Optional)
  nginx:
    image: nginx:alpine
    container_name: autoflow-nginx
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
    depends_on:
      - frontend
      - backend
    networks:
      - autoflow-network
    profiles:
      - production
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - NET_BIND_SERVICE

  # Database Backup Service (Optional)
  backup:
    image: alpine:latest
    container_name: autoflow-backup
    restart: unless-stopped
    volumes:
      - database_data:/data/db:ro
      - backup_data:/backup
    environment:
      - BACKUP_SCHEDULE=${BACKUP_SCHEDULE:-0 2 * * *}
    command: >
      sh -c "
        apk add --no-cache dcron &&
        echo '${BACKUP_SCHEDULE:-0 2 * * *} cp /data/db /backup/database_$$(date +%Y%m%d_%H%M%S).db && find /backup -name \"database_*.db\" -mtime +7 -delete' | crontab - &&
        crond -f
      "
    networks:
      - autoflow-network
    profiles:
      - production
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL

# Networks
networks:
  autoflow-network:
    driver: bridge
    name: autoflow-ai-network

# Volumes
volumes:
  database_data:
    driver: local
    name: autoflow-database
  backend_data:
    driver: local
    name: autoflow-backend-data
  backend_logs:
    driver: local
    name: autoflow-backend-logs
  backup_data:
    driver: local
    name: autoflow-backup-data
